#### CALL FOR PAPERS ***************************

Special issue of the ACM Journal of Data and Information Quality (ACM JDIQ) on Quality Assessment of Knowledge Graphs

#### Guest editors *****************************

- Anisa Rula, University of Milano-Bicocca and University of Bonn
- Elena Simperl, University of Southampton
- Amrapali Zaveri, Maastricht University
- Elena Demidova, L3S Research Center in Hannover

#### Important dates and timeline **************

- Initial submission:   March 3, 2019
- First review:   June 3, 2019
- Revised manuscripts:   August 3, 2019
- Second review:   October 3, 2019
- Camera-ready manuscripts:  December 3, 2019
- Publication:    February 2020

#### Context ***********************************

The information in Knowledge Graphs (KGs) comes in large quantities (volume), from heterogeneous sources
and in various format (variety), quickly evolves over time (velocity) and may be inconsistent (veracity) or
indicate other quality problems. In particular, several recent studies report that existing knowledge graphs
indicate significant differences with respect to the quality of information they contain.

Despite the quality of knowledge graphs being an essential concept for a variety of real-world applications,
few efforts are currently available to standardize how quality tracking and assurance of knowledge graphs
should be implemented. For traditional databases, numerous assessment methods have been proposed,
which focused on the definition and modeling of several data quality dimensions (or criteria), such as data
completeness, accuracy, timeliness, consistency or absence of duplicates. For the KGs new algorithms and
metrics have to be designed, in particular, in order to deal with novel requirements related to the variety,
volume and velocity issues. The new algorithms and metrics should consider the differences of the structural
characteristics between traditional databases and KGs. Understanding and managing the evolution of quality
dimensions, methods and techniques needed to assess quality in KGs is a challenge that needs to be
addressed. Moreover, none of the current approaches use the assessment to ultimately improve the quality in
the long run.

Knowledge graph profiling, i.e. extraction of metadata describing knowledge graph characteristics, is of
increasing importance in this context. Profiling can support efficient quality assessment especially for largescale
knowledge graphs, definition of quality rules in particular domains and generation of data summaries.
Of particular interest are the profiling methods in the novel application domains, including, for example,
knowledge graphs that contain geographical, temporal, event-centric and multilingual information as well as
application of knowledge graphs in the domain of machine learning.

This Special Issue is addressed to those members of the community interested in providing novel
methodologies or scalable frameworks in assessing, monitoring, maintaining and improving the quality of as
well as profiling of knowledge graphs and also introduce efficient tools, access methods and user interfaces
that can effectively assist in these processes. The benefits of such methodologies will not only help in
detecting inherent quality problems currently plaguing knowledge graphs, and make these characteristics
more transparent to applications and users, but also provide the means to fix these problems and maintain
the quality in the long run.

#### Topics *************************************

Specific topics within the scope of the call include, but are not limited to, the following:

- Knowledge Graph profile representation
- Knowledge Graph profiling approaches
- Profiling KGs containing geographical, temporal and event-centric information 
- Profiling multilingual Knowledge Graphs
- Profiling Knowledge Graphs for machine learning applications
- Adoption of Knowledge Graph profiles in question answering and data search
- Novel applications of Knowledge Graph profiles
- Data quality assessment frameworks for Knowledge Graphs Evaluation of data quality and trustworthiness
- Large-scale quality assessment of structured datasets
- Validation of currently existing data quality assessment methodologies
- Use-case driven quality assessment
- Design and implementation of data quality monitoring, assessment and improvement tools
- Quality exploration and analysis interfaces
- Scalability and performance of quality assessment tools
- Crowdsourcing quality assessment/improvement

#### Expected Contributions**********************

We welcome two types of regular contributions: 

- Research manuscripts reporting novel methodologies and results (up to 25 pages).

- Experience papers that report on lessons learned from addressing specific issues within the scope of the call. 
These papers should be of interest to the broad data quality community (10+ pages plus an optional appendix).

##### Format *************************************
   
JDIQ welcomes manuscripts that extend prior published work, provided they contain at least 30% new material, and that the significant 
new contributions are clearly identified in the introduction. 

Submission guidelines with Latex (preferred) or Word templates are available here: http://jdiq.acm.org/authors.cfm#subm 

Please submit the paper by selecting as type of submission: "SI: Quality Assessment of Knowledge Graphs"

##### Contacts ***********************************

For any question, do not hesitate to contact:

Anisa Rula 
Lead Guest Editor of the Special Issue
rula@disco.unimib.it