ï»¿CALL FOR PAPERS

SECOND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRAGMATICS (MMPrag'19)
March 30, 2019 - San Jose, California
Co-Located with the IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR'19)
March 28-30, 2019 - San Jose, California

Venue: Crowne Plaza San Jose-Silicon Valley Hotel, 777 Bellew Drive, Milpitas, California 95053, +1 (408) 321-9500

Submission Website: https://easychair.org/conferences/?conf=mmprag19
Call for Papers: https://easychair.org/cfp/MMPrag19
Workshop Website: http://mipr.sigappfr.org/19/

====================================IMPORTANT DATES====================================================================

January 25, 2019 - Submissions due 
February 1, 2019 - Acceptance notification 
February 8, 2019 - Camera-ready papers and author registrations due 
March 30, 2019   - Workshop date
 
====================================DESCRIPTION=========================================================================
Most multimedia objects are spatio-temporal simulacrums of the real world. This supports our view that the next grand challenge 
for our community will be understanding and formally modeling the flow of life around us, over many modalities and scales. As 
technology advances, the nature of these simulacrums will evolve as well, becoming more detailed and revealing more information
concerning the nature of reality to us.

Currently, IoT is the state-of-the-art organizational approach to construct complex representations of the flow of life around us. 
Various, perhaps pervasive, sensors, working collectively, will broadcast to us representations of real events in real-time. It 
will be our task to continuously extract the semantics of these representations and possibly react to them by injecting some 
response actions into the mix to ensure some desired outcome.

In linguistics, pragmatics studies context and how it affects semantics. Context is usually culturally, socially, and historically 
based. For example, pragmatics would encompass a speakerâ€™s intent, body language, and penchant for sarcasm, as well as other signs,  
often culturally based, such as the speakerâ€™s type of clothing, which could influence a statementâ€™s meaning. Generic signal/sensor- 
based retrieval should also use syntactical, semantic, and pragmatics-based approaches. If we are to understand and model the flow 
of life around us, this will be a necessity.

Our community hSecas successfully developed various approaches to decode the syntax and semantics of these artifacts. The development 
of techniques that use contextual information is in its infancy, however. With the expansion of the data horizon, through the 
ever-increasing use of metadata, we can certainly leverage the semantic representation of all media to a more robust level.

The NLP community has its own set of approaches in semantics and pragmatics. Natural language is certainly an excellent exemplar of 
multimedia, and the use of audio and text features has played a part in the development of our field.

After a successful first workshop in Miami, we intend to continue this tradition with the second workshop.

====================================AREAS===============================================================================

Authors are invited to submit regular papers (6 pages), short papers (4 pages), demo papers (4 pages), and extended abstracts (1 page max
for a 5-minute presentation) at https://easychair.org/conferences/?conf=mmprag19.

Cross-cultural contributions are encouraged. Topics of interest include, but are not limited to:

- Affective computing
- Annotation techniques for natural language/images/videos/other sensor-based modalities
- Applications to ecology, environmental science, health sciences, social sciences
- Computational semiotics
- Deception detection
- Digital humanities
- Distributional semantics
- Education and Tutoring Systems
- Event modeling, recognition, and understanding
- Gesture modeling, recognition, and understanding
- Human-machine interaction
- Integration of multimodal features
- Machine learning for multimodal interaction
- Multimodal analysis of human behavior
- Multimodal data modeling, dataset development, sensor fusion
- Ontologies
- Semantic-based modeling and retrieval
- Storytelling
- Structured semantic embeddings
- Word, sentence, and feature embeddings - generation, semantic property discovery, corpus dependencies,
  sensitivity analysis, retrieval aids

To be included in the IEEE Xplore Library, accepted papers must be registered and presented.


====================================ORGANIZATION========================================================================

Chairs: 
  R. Chbeir, University of Pau, FR (richard.chbeir@univ-pau.fr)
  W. Grosky, University of Michigan-Dearborn, US (wgrosky@umich.edu)

Program Committee:
  Wael Abd-Almageed, ISI, USA
  Mohamed Abouelenien, University of Michigan-Dearborn, USA
  Rajeev Agrawal, ITL, ERDC, USA
  Akiko Aizawa, National Institute of Informatics, Japan
  Yiannis Aloimonos, University of Maryland, USA
  Anya Belz, University of Brighton, UK
  Renaldo Bonacin, CTI, BrazilSecond
  Fabricio Olivetti de Franca, Federal University of ABC, Brazil
  Julia Hirschberg, Columbia University, USA
  David Hogg, University of Leeds, UK
  Ashutosh Jadhav, IBM, USA
  Clement Leung, Hong Kong Baptist University, China
  Debanjan Mahata, Bloomberg, USA
  David Martins, Federal University of ABC, Brazil
  Adam Pease, Articulate Software, USA
  James Pustejovsky, Brandeis University, USA
  Terry Ruas, University of Michigan-Dearborn, USA
  Victoria Rubin, University of Western Ontario, Canada
  Shin'ichi Satoh, National Institute of Informatics, Japan
  Amit Sheth, Wright State University, USA
  Peter Stanchev, Kettering University, USA
  Joe Tekli, American University of Lebanon, Lebanon